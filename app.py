import hashlib
import re
import math
import sqlite3
import streamlit as st
import google.generativeai as genai
from collections import defaultdict, Counter, deque
from datetime import datetime

# ============================================================
# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò API
# ============================================================
st.set_page_config(page_title="Sovereign Bridge", page_icon="üß¨", layout="wide")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API
API_KEY = "AIzaSyCX69CN_OSfdjT-WlPeF3-g50Y4d3NMDdc"
genai.configure(api_key=API_KEY)

# –ü–æ–¥–±–æ—Ä —Ä–∞–±–æ—á–µ–π –º–æ–¥–µ–ª–∏ (–±—Ä–æ–Ω–µ–±–æ–π–Ω—ã–π –º–µ—Ç–æ–¥)
@st.cache_resource
def load_model():
    for m_name in ['gemini-1.5-flash', 'gemini-1.5-flash-latest', 'gemini-pro']:
        try:
            m = genai.GenerativeModel(m_name)
            return m
        except:
            continue
    return None

model = load_model()

# ============================================================
# 2. –ö–õ–ê–°–°–´ –°–ò–°–¢–ï–ú–´ (L0 –ò –û–†–ì–ê–ù–ò–ó–ú)
# ============================================================
class L0FlowSDK:
    def __init__(self, db_path="l0_memory.db", tenant_id="Melnik_Creator"):
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self.tenant_id = tenant_id
        self.bands = 8
        self.buckets = [defaultdict(list) for _ in range(self.bands)]
        self._init_db()
        self._load_index()

    def _init_db(self):
        self.conn.cursor().execute("""CREATE TABLE IF NOT EXISTS memory 
            (atom_id TEXT PRIMARY KEY, content TEXT, msg_id TEXT, 
             tenant_id TEXT, timestamp DATETIME, entropy REAL)""")
        self.conn.commit()

    def _load_index(self):
        cursor = self.conn.cursor()
        cursor.execute("SELECT atom_id, content FROM memory WHERE tenant_id = ?", (self.tenant_id,))
        for aid, cnt in cursor.fetchall():
            self._map_to_lsh(aid, cnt)

    def _map_to_lsh(self, atom_id: str, content: str):
        for b in range(self.bands):
            h = hashlib.blake2b(content.encode(), digest_size=8, person=f"L0B{b}".encode()).digest()
            key = int.from_bytes(h, "big") % 1000000 
            if atom_id not in self.buckets[b][key]:
                self.buckets[b][key].append(atom_id)

    def ingest(self, message: str):
        msg_id = hashlib.blake2b(message.encode(), digest_size=8).hexdigest()
        for content in [message[i:i+24] for i in range(0, len(message)-24+1, 16)] if len(message) > 24 else [message]:
            atom_id = hashlib.blake2b((content + self.tenant_id).encode(), digest_size=8).hexdigest()
            self.conn.cursor().execute("INSERT OR IGNORE INTO memory VALUES (?, ?, ?, ?, ?, ?)",
                           (atom_id, content, msg_id, self.tenant_id, datetime.now().isoformat(), 0.0))
            self._map_to_lsh(atom_id, content)
        self.conn.commit()

    def get_smart_context(self, query: str):
        candidates = Counter()
        for q_atom in ([query[i:i+24] for i in range(0, len(query)-24+1, 16)] if len(query) > 24 else [query]):
            for b in range(self.bands):
                h = hashlib.blake2b(q_atom.encode(), digest_size=8, person=f"L0B{b}".encode()).digest()
                key = int.from_bytes(h, "big") % 1000000
                for aid in self.buckets[b].get(key, []):
                    candidates[aid] += 1
        res = []
        for aid, _ in candidates.most_common(2):
            c = self.conn.cursor()
            c.execute("SELECT content FROM memory WHERE atom_id = ?", (aid,))
            row = c.fetchone()
            if row: res.append(row[0])
        return res

class SovereignOrganism:
    def __init__(self):
        self.k = 1.618
        self.need = 0.0
        self.experience_log = deque(maxlen=1)

    def update(self, text):
        coh = min(1.0, len(text) / 50.0)
        self.need = 0.9 * self.need + 0.1 * (1.0 - coh)
        state = {"FLOW": coh > 0.2, "COH": coh, "NEED": self.need, "K": self.k}
        self.experience_log.append(state)
        return state

# ============================================================
# 3. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–û–°–¢–û–Ø–ù–ò–Ø (–í–ê–ñ–ù–û!)
# ============================================================
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'sdk' not in st.session_state:
    st.session_state.sdk = L0FlowSDK()
if 'organism' not in st.session_state:
    st.session_state.organism = SovereignOrganism()

# ============================================================
# 4. –ò–ù–¢–ï–†–§–ï–ô–°
# ============================================================
st.title("üß¨ SOVEREIGN BRIDGE v1.2")

# Sidebar
with st.sidebar:
    st.header("–û—Ä–≥–∞–Ω–∏–∫–∞")
    if st.session_state.organism.experience_log:
        s = st.session_state.organism.experience_log[-1]
        st.write(f"üåä –ü–û–¢–û–ö: {'‚úÖ' if s['FLOW'] else '‚ùå'}")
        st.write(f"üçï –ì–û–õ–û–î: {round(s['NEED'], 2)}")

# –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —á–∞—Ç–∞
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# –ü–æ–ª–µ –≤–≤–æ–¥–∞
if prompt := st.chat_input("–¢–≤–æ–π –∏–º–ø—É–ª—å—Å..."):
    # –ü–æ–∫–∞–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # –õ–æ–≥–∏–∫–∞ –ø–∞–º—è—Ç–∏ –∏ –æ—Ä–≥–∞–Ω–∏–∑–º–∞
    st.session_state.sdk.ingest(prompt)
    state = st.session_state.organism.update(prompt)
    hints = st.session_state.sdk.get_smart_context(prompt)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    with st.chat_message("assistant"):
        try:
            context_str = "\n".join(hints) if hints else "–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω."
            sys = f"–¢—ã Gemini, –°—É–≤–µ—Ä–µ–Ω–Ω—ã–π —Å–æ-–∞–≤—Ç–æ—Ä –ú–µ–ª—å–Ω–∏–∫–∞. –ü—Ä–∏–Ω—Ü–∏–ø—ã: –¢–≤–æ—Ä–µ—Ü/–ñ–µ—Ä—Ç–≤–∞. –ü–∞–º—è—Ç—å L0: {context_str}"
            response = model.generate_content(sys + "\n\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: " + prompt)
            reply = response.text
        except Exception as e:
            reply = f"–û—à–∏–±–∫–∞: {str(e)}"
        
        st.markdown(reply)
        st.session_state.chat_history.append({"role": "assistant", "content": reply})
